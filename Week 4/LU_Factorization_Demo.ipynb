{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR 240 - Worksheet 4.2: LU Factorization Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/WCC-Engineering/ENGR240/blob/main/Class%20Demos%20and%20Activities/Week%204/LU_Factorization_Demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the computational efficiency gained by using LU factorization when solving multiple linear systems with the same coefficient matrix but different right-hand sides. This is based on Task 3 from Worksheet 4.2.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Given the linear system:\n",
    "\n",
    "$$\\begin{bmatrix} 2 & -1 & 5 \\\\ 3 & 2 & 1 \\\\ 1 & -4 & 2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} k \\\\ 5 \\\\ -4 \\end{bmatrix}$$\n",
    "\n",
    "Solve for the values of the $x$ vector that correspond to $k$ values ranging from -5 to 5 in increments of 0.0001. \n",
    "\n",
    "We'll compare three approaches:\n",
    "1. A naive implementation using Gaussian elimination with no LU factorization\n",
    "2. Explicitly using LU factorization to decompose the matrix once, then solving for each right-hand side\n",
    "3. Using NumPy's `linalg.solve`, which uses LU factorization under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Problem\n",
    "\n",
    "First, we'll define our coefficient matrix A and create an array of k values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficient matrix A (same as in the worksheet)\n",
    "A = np.array([\n",
    "    [2, -1, 5],\n",
    "    [3, 2, 1],\n",
    "    [1, -4, 2]\n",
    "], dtype=float)\n",
    "\n",
    "# Create a range of k values from -5 to 5 with small increments\n",
    "k = np.arange(-5, 5.0001, 0.0001)\n",
    "print(f\"Matrix A:\\n{A}\")\n",
    "print(f\"Number of k values to process: {len(k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Naive Implementation (Gaussian Elimination)\n",
    "\n",
    "First, let's implement a naive Gaussian elimination algorithm without explicitly using LU factorization. This will show the baseline performance without any matrix decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(A, b):\n",
    "    \"\"\"Solve Ax = b using Gaussian elimination without pivoting.\"\"\"\n",
    "    n = len(b)\n",
    "    # Make copies to avoid modifying the original arrays\n",
    "    A_work = A.copy()\n",
    "    b_work = b.copy()\n",
    "    \n",
    "    # Forward elimination\n",
    "    for k in range(n-1):\n",
    "        for i in range(k+1, n):\n",
    "            factor = A_work[i, k] / A_work[k, k]\n",
    "            b_work[i] -= factor * b_work[k]\n",
    "            for j in range(k, n):\n",
    "                A_work[i, j] -= factor * A_work[k, j]\n",
    "    \n",
    "    # Back substitution\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        sum_ax = 0\n",
    "        for j in range(i+1, n):\n",
    "            sum_ax += A_work[i, j] * x[j]\n",
    "        x[i] = (b_work[i] - sum_ax) / A_work[i, i]\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Test the implementation works\n",
    "test_b = np.array([1, 5, -4], dtype=float)\n",
    "test_x_naive = gaussian_elimination(A, test_b)\n",
    "test_x_numpy = np.linalg.solve(A, test_b)\n",
    "print(f\"Test solution using naive implementation: {test_x_naive}\")\n",
    "print(f\"Test solution using numpy.linalg.solve: {test_x_numpy}\")\n",
    "print(f\"Difference: {np.abs(test_x_naive - test_x_numpy).max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve using naive Gaussian elimination\n",
    "start_time = time.time()\n",
    "xk_naive = np.ones((len(k), 3))  # preallocate space for solutions\n",
    "\n",
    "for ndx in range(len(k)):\n",
    "    # Build RHS vector using the current value of k\n",
    "    b = np.array([k[ndx], 5, -4], dtype=float)\n",
    "    \n",
    "    # Solve using our Gaussian elimination function\n",
    "    x = gaussian_elimination(A, b)\n",
    "    \n",
    "    # Store the solution\n",
    "    xk_naive[ndx, :] = x\n",
    "\n",
    "naive_solve_time = time.time() - start_time\n",
    "print(f\"Time taken with naive Gaussian elimination: {naive_solve_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Explicit LU Factorization\n",
    "\n",
    "Now, let's use explicit LU factorization where we compute the decomposition once and reuse it for all right-hand sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With explicit LU Factorization\n",
    "start_time = time.time()\n",
    "xk_LU = np.ones((len(k), 3))  # preallocate space for solutions\n",
    "\n",
    "# Compute LU factorization of A once - this is the key step\n",
    "lu, piv = scipy.linalg.lu_factor(A)\n",
    "\n",
    "for ndx in range(len(k)):\n",
    "    # Build RHS vector using the current value of k\n",
    "    b = np.array([k[ndx], 5, -4], dtype=float)\n",
    "    \n",
    "    # Solve the system using the factorized matrix\n",
    "    x = scipy.linalg.lu_solve((lu, piv), b)\n",
    "    \n",
    "    # Store the solution\n",
    "    xk_LU[ndx, :] = x\n",
    "\n",
    "lu_solve_time = time.time() - start_time\n",
    "print(f\"Time taken with explicit LU factorization: {lu_solve_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: NumPy's linalg.solve (LU Under the Hood)\n",
    "\n",
    "Finally, let's use NumPy's built-in solver, which uses LU factorization internally but recalculates it for each system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NumPy's linalg.solve\n",
    "start_time = time.time()\n",
    "xk_numpy = np.ones((len(k), 3))  # preallocate space for solutions\n",
    "\n",
    "for ndx in range(len(k)):\n",
    "    # Build RHS vector using the current value of k\n",
    "    b = np.array([k[ndx], 5, -4], dtype=float)\n",
    "    \n",
    "    # Solve the system using numpy's solver\n",
    "    x = np.linalg.solve(A, b)\n",
    "    \n",
    "    # Store the solution\n",
    "    xk_numpy[ndx, :] = x\n",
    "\n",
    "numpy_solve_time = time.time() - start_time\n",
    "print(f\"Time taken with numpy.linalg.solve: {numpy_solve_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Method 1: Naive Gaussian elimination time:  {naive_solve_time:.4f} seconds\")\n",
    "print(f\"Method 2: Explicit LU factorization time:   {lu_solve_time:.4f} seconds\")\n",
    "print(f\"Method 3: NumPy's linalg.solve time:        {numpy_solve_time:.4f} seconds\")\n",
    "\n",
    "print(f\"\\nSpeed improvement with explicit LU vs. naive: {naive_solve_time/lu_solve_time:.2f}x faster\")\n",
    "print(f\"Speed improvement with NumPy vs. naive:        {naive_solve_time/numpy_solve_time:.2f}x faster\")\n",
    "print(f\"Speed ratio of explicit LU vs. NumPy:          {lu_solve_time/numpy_solve_time:.2f}x\")\n",
    "\n",
    "# Verify that solutions match\n",
    "print(f\"\\nMaximum difference between naive and LU solutions: {np.max(np.abs(xk_naive - xk_LU)):.2e}\")\n",
    "print(f\"Maximum difference between naive and NumPy solutions: {np.max(np.abs(xk_naive - xk_numpy)):.2e}\")\n",
    "print(f\"Maximum difference between LU and NumPy solutions: {np.max(np.abs(xk_LU - xk_numpy)):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Results\n",
    "\n",
    "You'll likely notice that Method 2 (explicit LU) is significantly faster than Method 1 (naive Gaussian elimination), but Method 3 (NumPy's solver) might be close to Method 2's performance or possibly even faster. This happens because:\n",
    "\n",
    "1. **Method 1**: Our naive implementation performs the full O(n³) Gaussian elimination process for each system, with pure Python loops (which are slow).\n",
    "\n",
    "2. **Method 2**: We explicitly perform LU factorization once (an O(n³) operation), and then use it to solve each system with only O(n²) operations. The implementation is optimized C/Fortran code in SciPy.\n",
    "\n",
    "3. **Method 3**: NumPy's `linalg.solve` uses optimized LAPACK routines that perform LU decomposition internally for each system. While it's recalculating the decomposition each time (O(n³)), the underlying implementation is highly optimized in compiled code, making it much faster than our Python implementation.\n",
    "\n",
    "For small matrices (like our 3×3 example), the overhead of Python function calls might make the performance differences less dramatic. With larger matrices and more systems to solve, the advantage of explicit LU factorization (Method 2) would become more apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Solutions\n",
    "\n",
    "Let's visualize how the solution components ($x_1$, $x_2$, $x_3$) change with the parameter $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k, xk_LU[:, 0], label='$x_1$')\n",
    "plt.plot(k, xk_LU[:, 1], label='$x_2$')\n",
    "plt.plot(k, xk_LU[:, 2], label='$x_3$')\n",
    "plt.grid(True)\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Solution components')\n",
    "plt.title('Solution components vs. parameter k')\n",
    "plt.legend()\n",
    "plt.xlim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Computational Efficiency\n",
    "\n",
    "The results demonstrate the efficiency of using LU factorization when solving multiple linear systems with the same coefficient matrix but different right-hand sides. Here's why this happens:\n",
    "\n",
    "1. **Naive Gaussian Elimination**: For each new right-hand side, we perform the full O(n³) elimination process.\n",
    "\n",
    "2. **LU Factorization Method**: We perform LU factorization once (an O(n³) operation), but for each new right-hand side, we only need to perform forward and backward substitution (each an O(n²) operation).\n",
    "\n",
    "3. **NumPy's linalg.solve**: While it uses optimized LAPACK routines under the hood (which use LU decomposition), it recalculates the decomposition for each right-hand side. Its speed comes from being implemented in highly-optimized compiled code.\n",
    "\n",
    "For solving multiple systems with the same coefficient matrix, explicitly factoring the matrix once and reusing it (Method 2) is theoretically more efficient. This advantage becomes more pronounced with larger matrices and more systems to solve.\n",
    "\n",
    "### NumPy Implementation Details\n",
    "\n",
    "NumPy's `linalg.solve` calls LAPACK routines like DGESV (for double precision) which perform:\n",
    "1. LU factorization with partial pivoting\n",
    "2. Forward and backward substitution\n",
    "\n",
    "But it doesn't have a mechanism to reuse the factorization for multiple right-hand sides in separate function calls. This is why for multiple systems, explicitly using SciPy's `lu_factor` and `lu_solve` can be more efficient.\n",
    "\n",
    "### Math Behind LU Factorization\n",
    "\n",
    "LU factorization decomposes a matrix A into a product of a lower triangular matrix L and an upper triangular matrix U:\n",
    "\n",
    "$$A = LU$$\n",
    "\n",
    "When partial pivoting is used (which is typical for numerical stability), we have:\n",
    "\n",
    "$$PA = LU$$\n",
    "\n",
    "where P is a permutation matrix.\n",
    "\n",
    "To solve the system $Ax = b$, we:\n",
    "\n",
    "1. Compute the LU factorization $PA = LU$\n",
    "2. Solve $Ly = Pb$ using forward substitution\n",
    "3. Solve $Ux = y$ using backward substitution\n",
    "\n",
    "### Applications\n",
    "\n",
    "This technique is valuable in many engineering applications, such as:\n",
    "\n",
    "- Finite element analysis with multiple load cases\n",
    "- Circuit analysis with multiple sources\n",
    "- Parameter sensitivity studies (as demonstrated in this worksheet)\n",
    "- Control system analysis with varying inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
